{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "955c7939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "try:\n",
    "    envPath = find_dotenv()\n",
    "\n",
    "    if not envPath:\n",
    "        raise ModuleNotFoundError(\".env FILE NOT FOUND\")\n",
    "    if not load_dotenv(envPath):\n",
    "        raise EnvironmentError(\"FAILED TO LOAD .env\")\n",
    "    \n",
    "    openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    openai_model = os.environ.get(\"OPENAI_MODEL\")\n",
    "\n",
    "    if not openai_api_key:\n",
    "        raise ValueError(\"API NOT FOUND\")\n",
    "    if not openai_model:\n",
    "        raise ValueError(\"MODEL NOT FOUND\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: {e}\")\n",
    "    openai_api_key, openai_model = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bb779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict, Sequence\n",
    "import operator, json\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b86967a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model = openai_model, api_key = openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6df13dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hi there\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "365d8c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'President of the United States - Wikipedia',\n",
       "  'url': 'https://en.wikipedia.org/wiki/President_of_the_United_States',\n",
       "  'content': '*   [Minority Leader](https://en.wikipedia.org/wiki/Party_leaders_of_the_United_States_Senate \"Party leaders of the United States Senate\")[Chuck Schumer](https://en.wikipedia.org/wiki/Chuck_Schumer \"Chuck Schumer\") (D)\\n[Executive](https://en.wikipedia.org/wiki/Executive_branch_of_the_United_States \"Executive branch of the United States\")\\n\\n*   **President of the United States**\\n\\n*   [Donald Trump](https://en.wikipedia.org/wiki/Donald_Trump \"Donald Trump\") (R) [...] resignation\").[[C]](https://en.wikipedia.org/wiki/President_of_the_United_States#cite_note-22) In all, [45 individuals](https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States \"List of presidents of the United States\") have served 47 presidencies spanning 60 four-year terms.[[D]](https://en.wikipedia.org/wiki/President_of_the_United_States#cite_note-24)[Donald Trump](https://en.wikipedia.org/wiki/Donald_Trump \"Donald Trump\") is the 47th and current president since January 20, [...] Nixon](https://en.wikipedia.org/wiki/Richard_Nixon \"Richard Nixon\"), [Ronald Reagan](https://en.wikipedia.org/wiki/Ronald_Reagan \"Ronald Reagan\"), [Theodore Roosevelt](https://en.wikipedia.org/wiki/Theodore_Roosevelt \"Theodore Roosevelt\"), [William Howard Taft](https://en.wikipedia.org/wiki/William_Howard_Taft \"William Howard Taft\"), and **[Donald Trump](https://en.wikipedia.org/wiki/Donald_Trump \"Donald Trump\") (incumbent)** |',\n",
       "  'score': 0.8124067},\n",
       " {'title': 'President of the United States',\n",
       "  'url': 'https://usun.usmission.gov/our-leaders/the-president-of-the-united-states/',\n",
       "  'content': '*   [Remarks and Highlights](https://usun.usmission.gov/category/remarks-and-highlights/)\\n\\nPresident of the United States\\n==============================\\n\\n[Home](https://usun.usmission.gov/)[Home](https://usun.usmission.gov/) | [Our Leaders](https://usun.usmission.gov/our-leaders/) | President of the United States\\n\\n![Image 2](https://edit.usembassy.gov/wp-content/uploads/Donald-J-Trump-600x600-1.png)\\n\\n### President Donald J. Trump',\n",
       "  'score': 0.756376},\n",
       " {'title': 'The White House',\n",
       "  'url': 'https://www.whitehouse.gov/',\n",
       "  'content': '*   [Administration](https://www.whitehouse.gov/administration/)\\n    *   [Donald J. Trump](https://www.whitehouse.gov/administration/donald-j-trump/)\\n    *   [JD Vance](https://www.whitehouse.gov/administration/jd-vance/)\\n    *   [Melania Trump](https://www.whitehouse.gov/administration/melania-trump/)\\n    *   [Usha Vance](https://www.whitehouse.gov/administration/usha-vance/)\\n    *   [The Cabinet](https://www.whitehouse.gov/administration/the-cabinet/)',\n",
       "  'score': 0.69024646}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplication Tool\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def search(query: str):\n",
    "    \"\"\"Search Tool\"\"\"\n",
    "    tavily = TavilySearchResults()\n",
    "    result = tavily.invoke(query)\n",
    "    return result\n",
    "\n",
    "search('Who is the president of USA?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11c7453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search, multiply]\n",
    "\n",
    "llmWithTools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a79ce471",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_mapping = {tool.name: tool for tool in tools}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95212219",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState:\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "def invokeModel(state: AgentState):\n",
    "    messages = state['messages']\n",
    "    question = messages[-1]\n",
    "    return {'messages': [llmWithTools.invoke(question)]}\n",
    "\n",
    "def invookeTool(state: AgentState):\n",
    "    tool_details = state['messages'][-1].additional_kwargs.get(\"tool_calls\", [])[0]\n",
    "\n",
    "    if tool_details is None:\n",
    "        raise Exception(\"No tool call found\")\n",
    "    \n",
    "    print(f\"Selected Tool: {tool_details.get(\"function\").get(\"name\")}\")\n",
    "\n",
    "    if tool_details.get(\"function\").get(\"name\") == \"search\":\n",
    "        response = input(prompt = f\"[y/n] continue with expensive web search? \")\n",
    "\n",
    "        if response.lower() == 'n':\n",
    "            raise Exception(\"Web Search Discard\")\n",
    "    \n",
    "    response = tool_mapping[tool_details['function']['name'].invoke(json.loads(tool_details.get(\"function\".get(\"name\"))))]\n",
    "    return {'messages': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f10b079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state):\n",
    "    tool_calls = state['messages'][-1].additional_kwargs.get(\"tool_calls\", [])\n",
    "\n",
    "    if len(tool_calls):\n",
    "        return \"tool\"\n",
    "    return \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f52592d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7900ac8b4e00>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"ai_assistant\", invokeModel)\n",
    "graph.add_node(\"tool\", invokeModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "57b968e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AgentState() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m app = graph.compile()\n\u001b[32m      7\u001b[39m app\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mWho is the upcoming Prime Minister of Pakistan?\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mValue at \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mvalue\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SiRiiL/venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2433\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2427\u001b[39m     get_waiter = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m   2428\u001b[39m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2429\u001b[39m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2430\u001b[39m \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2431\u001b[39m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2432\u001b[39m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2433\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_channels\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   2434\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2435\u001b[39m         loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SiRiiL/venv/lib/python3.12/site-packages/langgraph/pregel/loop.py:553\u001b[39m, in \u001b[36mPregelLoop.tick\u001b[39m\u001b[34m(self, input_keys)\u001b[39m\n\u001b[32m    550\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    552\u001b[39m \u001b[38;5;66;03m# prepare next tasks\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m \u001b[38;5;28mself\u001b[39m.tasks = \u001b[43mprepare_next_tasks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint_pending_writes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmanaged\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfor_execution\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupdated_channels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupdated_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[38;5;28mself\u001b[39m.to_interrupt = []\n\u001b[32m    572\u001b[39m \u001b[38;5;66;03m# produce debug output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SiRiiL/venv/lib/python3.12/site-packages/langgraph/pregel/algo.py:495\u001b[39m, in \u001b[36mprepare_next_tasks\u001b[39m\u001b[34m(checkpoint, pending_writes, processes, channels, managed, config, step, for_execution, store, checkpointer, manager, trigger_to_nodes, updated_channels, retry_policy, cache_policy)\u001b[39m\n\u001b[32m    492\u001b[39m \u001b[38;5;66;03m# Check if any processes should be run in next step\u001b[39;00m\n\u001b[32m    493\u001b[39m \u001b[38;5;66;03m# If so, prepare the values to be passed to them\u001b[39;00m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m candidate_nodes:\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m task := \u001b[43mprepare_single_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mPULL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_id_bytes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_id_bytes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_null_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnull_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpending_writes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpending_writes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmanaged\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanaged\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfor_execution\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfor_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    515\u001b[39m         tasks.append(task)\n\u001b[32m    516\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {t.id: t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tasks}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SiRiiL/venv/lib/python3.12/site-packages/langgraph/pregel/algo.py:789\u001b[39m, in \u001b[36mprepare_single_task\u001b[39m\u001b[34m(task_path, task_id_checksum, checkpoint, checkpoint_id_bytes, checkpoint_null_version, pending_writes, processes, channels, managed, config, step, for_execution, store, checkpointer, manager, input_cache, cache_policy, retry_policy)\u001b[39m\n\u001b[32m    787\u001b[39m triggers = \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28msorted\u001b[39m(proc.triggers))\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     val = \u001b[43m_proc_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmanaged\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfor_execution\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfor_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    796\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m MISSING:\n\u001b[32m    797\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SiRiiL/venv/lib/python3.12/site-packages/langgraph/pregel/algo.py:1048\u001b[39m, in \u001b[36m_proc_input\u001b[39m\u001b[34m(proc, managed, channels, for_execution, input_cache)\u001b[39m\n\u001b[32m   1046\u001b[39m \u001b[38;5;66;03m# If the process has a mapper, apply it to the value\u001b[39;00m\n\u001b[32m   1047\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m for_execution \u001b[38;5;129;01mand\u001b[39;00m proc.mapper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1048\u001b[39m     val = \u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[38;5;66;03m# Cache the input value\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m input_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SiRiiL/venv/lib/python3.12/site-packages/langgraph/graph/state.py:1050\u001b[39m, in \u001b[36m_coerce_state\u001b[39m\u001b[34m(schema, input)\u001b[39m\n\u001b[32m   1049\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_coerce_state\u001b[39m(schema: \u001b[38;5;28mtype\u001b[39m[Any], \u001b[38;5;28minput\u001b[39m: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m-> \u001b[39m\u001b[32m1050\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: AgentState() takes no arguments",
      "Before task with name 'ai_assistant' and path '('__pregel_pull', 'ai_assistant')'"
     ]
    }
   ],
   "source": [
    "graph.add_conditional_edges(\"ai_assistant\", router, {\"tool\": \"tool\", \"end\": END})\n",
    "graph.add_edge(\"tool\", END)\n",
    "\n",
    "graph.set_entry_point(\"ai_assistant\")\n",
    "\n",
    "app = graph.compile()\n",
    "app\n",
    "\n",
    "for s in app.stream({'messages': ['Who is the upcoming Prime Minister of Pakistan?']}):\n",
    "    for key, value in s.items():\n",
    "        print(f\"Value at {key}: {value}\")\n",
    "        print(\"*\"*15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d967f2cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
